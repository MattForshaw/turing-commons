# Activity 7: Developing Case Studies [3]
###### tags: `RRI Course (Nov 2021)`

:::warning
This is the collaborative document for 'Group 3'. 

The following documents are for the other groups:

- [Group 1](https://hackmd.io/@cburr/B1EYmvpLF)
- [Group 2](https://hackmd.io/@cburr/B1Qx4v68Y)
:::

## Classifying Hate Speech

You are a team of social data scientists employed as consultants for a social media company. You have been tasked with reducing the levels of hate speech on the company's platform by developing a classifier that can flag potential instances of hate speech for review by human moderators. The tool will automatically review every post submitted to the platform, but will only flag those that are likely to represent an instance of hate speech, based on whether they exceed some likelihood threshold. In addition to the textual content contained within the post, your tool can also use a variety of other input sources to improve its decision-making, including feedback from the human moderators that help improve the accuracy of the model over time. 

| Category | Details |
| --- | --- |
|*Type of technology:*| Hate Speech Classifier|
|*Context of Use:*| Social Media Platform|
|*Outcome:*| Binary variable ('hate speech' or 'not hate speech') with confidence rating |
|*Project Team:*| Social Media Consultants and Platform|
|*Data Types:*| `Text content of post`, `Links or URLs`, `Network or connections of user`, `Tags`, `Images`, `Use of emojis`, `Liked communities`, `Stored cookies`, `Moderator feedback`|
|*Data Source(s):*| Social Media Company Data |

## Developments

- Write here

## Questions

- Write here
